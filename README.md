# SimpleTransformer

Transformer architecture according to article 'Attention Is All You Need'.


## Attention

```math
Attention(Q,K,V) = Softmax(\frac{Q K^{T}}{\sqrt{d_{k}}})
```
